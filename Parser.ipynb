{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from urllib import urlopen\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import csv\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_type = \"pub\"  # Choose: restaurant, cafe, coffee, pub\n",
    "URL = \"https://restoran.kz/\"+place_type\n",
    "df = place_type+'1'+'.csv'\n",
    "HEADERS = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.75 Safari/537.36',\n",
    "           'accept': '*/*'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url, params=None):\n",
    "    r = requests.get(url, headers=HEADERS, params=params)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWorkTime(link):\n",
    "    pattern_1='<div class=\"place-info-list__item\"><span class=\"place-info-list__icon\">⌚️<\\/span><span class=\"place-info-list__text\">(.{1,}?)<\\/span><\\/div>'\n",
    "    try:\n",
    "        with urllib.request.urlopen(link) as response:\n",
    "            html = response.read().decode('utf-8')\n",
    "        oo=re.findall(pattern_1, html)\n",
    "    except urllib.error.HTTPError:\n",
    "        oo=\"Не указано\"\n",
    "    return oo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content(html):\n",
    "    soup = bs(html, 'html.parser')\n",
    "    places = soup.find_all('div', class_='place-list-card__body')\n",
    "\n",
    "    arr = []\n",
    "    for place in places:\n",
    "        reserv = place.find('a', class_='btn btn-primary')\n",
    "        if reserv:\n",
    "            reserv = 1\n",
    "        else:\n",
    "            reserv = 0\n",
    "\n",
    "        reviews = place.find('a', class_='text-small')\n",
    "        if reviews:\n",
    "            reviews = reviews.get_text(strip=True)\n",
    "        else:\n",
    "            reviews = 'No reviews'\n",
    "\n",
    "        extra = place.find('div', class_='list-unstyled mb-4').find_next('li').find_next('li').find_next('li')\n",
    "        if extra:\n",
    "            extra = extra.get_text(strip = True)\n",
    "        else:\n",
    "            extra = 'No extra'\n",
    "\n",
    "        cuisine = place.find('div', class_='list-unstyled mb-4').find_next('li')\n",
    "        if cuisine:\n",
    "            cuisine = cuisine.get_text(strip=True)\n",
    "        else:\n",
    "            cuisine = 'No cuisine'\n",
    "\n",
    "        address = place.find('p', class_='place-list-card__subtitle')\n",
    "        if address:\n",
    "            address = address.get_text(strip=True)\n",
    "        else:\n",
    "            address = 'No address information'\n",
    "\n",
    "        price = place.find('div', class_='list-unstyled mb-4').find_next('li').find_next('li')\n",
    "        if price:\n",
    "            price = price.get_text(strip=True)\n",
    "        else:\n",
    "            price = 'No price information'\n",
    "\n",
    "        inside_link = \"https://restoran.kz\" + place.find('a', class_='link-inherit-color').get('href')\n",
    "        if (getWorkTime(inside_link)):\n",
    "            time = getWorkTime(inside_link)\n",
    "        else:\n",
    "            time = 'Не указано'\n",
    "\n",
    "        arr.append({\n",
    "            'Name': place.find('a', class_='link-inherit-color').get_text(strip=True),\n",
    "            'Type': place_type,\n",
    "            'Address': address,\n",
    "            'Cuisine type': cuisine,\n",
    "            'Price': price,\n",
    "            'Extra': extra,\n",
    "            'Reservation': reserv,\n",
    "            'Number of reviews': reviews,\n",
    "            'Working Hours': time\n",
    "            # 'Rating': place.find('span', class_ = 'rating-stars rating-stars_star_0')['aria-label']\n",
    "        })\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csv(items, path):\n",
    "    with open(path, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file, delimiter=';')\n",
    "        writer.writerow(['Name', 'Type', 'Address', 'Cuisine type', 'Price', 'Extra', 'Reservation', 'Number of reviews', 'Working Hours'])\n",
    "        for item in items:\n",
    "            writer.writerow([item['Name'], item['Type'], item['Address'], item['Cuisine type'],\n",
    "                             item['Price'], item['Extra'], item['Reservation'], item['Number of reviews'], item['Working Hours']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse():\n",
    "    html = get_html(URL)\n",
    "    if html.status_code == 200:\n",
    "        arr = []\n",
    "        errors = []\n",
    "        # change range parameter with corresponding maximum page:\n",
    "        # 29 - restaurants, 40 - cafe, 12 - coffee shop, 16 - pubs\n",
    "        if place_type == \"restaurant\":\n",
    "            pages = 29\n",
    "        elif place_type == \"cafe\":\n",
    "            pages = 40\n",
    "        elif place_type == \"coffee\":\n",
    "            pages = 12\n",
    "        elif place_type == \"pub\":\n",
    "            pages = 16\n",
    "\n",
    "        for page in range(1, pages+1):\n",
    "            print(f'Parsing of page number {page}')\n",
    "            html = get_html(URL, params={'page': page})\n",
    "            arr.extend(get_content(html.text))\n",
    "        to_csv(arr, df)\n",
    "        # print(arr)\n",
    "        # print(f'Number of parsed restaurants: {len(arr)}')\n",
    "    else:\n",
    "        print(\"Wrong url\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing of page number 1\n",
      "Parsing of page number 2\n",
      "Parsing of page number 3\n",
      "Parsing of page number 4\n",
      "Parsing of page number 5\n",
      "Parsing of page number 6\n",
      "Parsing of page number 7\n",
      "Parsing of page number 8\n",
      "Parsing of page number 9\n",
      "Parsing of page number 10\n",
      "Parsing of page number 11\n",
      "Parsing of page number 12\n",
      "Parsing of page number 13\n",
      "Parsing of page number 14\n",
      "Parsing of page number 15\n",
      "Parsing of page number 16\n"
     ]
    }
   ],
   "source": [
    "parse()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
